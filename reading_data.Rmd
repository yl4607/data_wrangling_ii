---
title: "Reading Data"
output: github_document
---

two major paths
1) data included as content on a webpage
2) dedicated server holding data in a relatively usable form

scrape web content

CSS Selector - selector gadget

rvest facilitates web scraping

APIs
Application Programming Interfaces 
give you a way to request specific data from a server
web APIs aren't uniform
"lucky" case, you can request a CSV from API
more general cases you'll get JavaScript Object Notation (JSON)


 
```{r setup}
library(tidyverse)
library(rvest)
library(httr)
```

## Scrape a table

I want the first table from [this page]
(http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm) 

read in the html

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

drug_use_html = read_html(url)
```

extract the table(s); focus on the first one

```{r}
tabl_marj = 
  drug_use_html %>% 
  html_nodes(css = "table") %>% 
  first() %>%
  html_table() %>% #view()
  slice(-1) %>% #remove first row
  as_tibble()
```

## Star War Movie info

data from (https://www.imdb.com/list/ls070150896/)

```{r}
url = "https://www.imdb.com/list/ls070150896/"

swm_html = read_html(url)
```

Grab elements that I want.

```{r}
title_vec = 
  swm_html %>% 
  html_nodes(css = ".lister-item-header a") %>% 
  html_text()

gross_rev_vec = 
  swm_html %>% 
  html_nodes(css = ".text-small:nth-child(7) span:nth-child(5)") %>% 
  html_text()

runtime_vec =
  swm_html %>% 
  html_nodes(css = ".runtime") %>% 
  html_text()

swm_df =
  tibble(
    title = title_vec,
    gross_rev = gross_rev_vec,
    runtime = runtime_vec
  )
```

## Get some water data

from API

```{r}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.csv") %>% 
  content("parsed")


nyc_water = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.json") %>% 
  content("text") %>% 
# more flexible?
  jsonlite::fromJSON() %>% 
  as.tibble()
```

##BRFSS

data from (https://chronicdata.cdc.gov/resource/acme-vg9e.csv)

```{r}
brfss_2010 = 
  GET("https://chronicdata.cdc.gov/resource/acme-vg9e.csv",
      query = list("$limit" = 5000)) %>% 
  content("parsed")  
#134K rows in the websites but shows only 1000 rows; default limit to 1000
```

## Some data aren't so nice

Let's look at Pokemon

```{r}
pokemon_data = 
  GET("http://pokeapi.co/api/v2/pokemon/1") %>% 
  content

pokemon_data$name
pokemon_data$height
pokemon_data$abilities
```

## Closing thoughts 

